import os, json, argparse
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import joblib

OUTDIR = "backend/model"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ====== MLP (í•™ìŠµ ë•Œì™€ ë™ì¼) ======
class MLP(nn.Module):
    def __init__(self, in_dim, n_classes, hidden=(256,128,64,32), dropout=0.2,
                 norm='batch', residual_every=0):
        super().__init__()
        assert len(hidden) >= 1
        self.n_classes = n_classes
        self.residual_every = int(residual_every) if residual_every else 0

        def make_norm(d):
            if norm == 'batch': return nn.BatchNorm1d(d)
            if norm == 'layer': return nn.LayerNorm(d)
            return nn.Identity()

        drops = list(dropout) if isinstance(dropout, (list, tuple)) else [float(dropout)]
        while len(drops) < len(hidden): drops.append(drops[-1])

        layers = []; prev = in_dim
        self.proj_for_res = nn.ModuleDict()
        for i, h in enumerate(hidden, start=1):
            block = [nn.Linear(prev, h), make_norm(h), nn.GELU(), nn.Dropout(drops[i-1])]
            layers.append(nn.Sequential(*block))
            if self.residual_every and (i % self.residual_every == 0):
                key = f"{i}_proj"
                self.proj_for_res[key] = nn.Linear(prev, h) if prev != h else nn.Identity()
            prev = h

        self.blocks = nn.ModuleList(layers)
        self.head = nn.Linear(prev, 1 if n_classes == 2 else n_classes)

    def forward(self, x):
        z = x
        for i, blk in enumerate(self.blocks, start=1):
            h = blk(z)
            if self.residual_every and (i % self.residual_every == 0):
                z = h + self.proj_for_res[f"{i}_proj"](z)
            else:
                z = h
        return self.head(z)

# ====== ë¡œë“œ & ìœ í‹¸ ======
def load_ckpt():
    path = os.path.join(OUTDIR, "best_model.pt")
    if not os.path.exists(path):
        raise FileNotFoundError(f"not found: {path}")
    return torch.load(path, map_location="cpu")

def build_model(ckpt):
    model = MLP(
        in_dim=ckpt["in_dim"],
        n_classes=ckpt["n_classes"],
        hidden=tuple(ckpt["hidden"]),
        dropout=ckpt["dropout"],
        norm=ckpt.get("norm", "batch"),
        residual_every=ckpt.get("residual_every", 0),
    )
    model.load_state_dict({k: v for k, v in ckpt["model_state"].items()})
    model.to(device).eval()
    return model

def align_features(df, feature_cols):
    for c in feature_cols:
        if c not in df.columns:
            df[c] = np.nan
    X = df[feature_cols].values.astype(np.float32)
    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
    return X

@torch.no_grad()
def infer(model, X, n_classes, batch_size=512):
    probs_list, preds_list = [], []
    for i in range(0, len(X), batch_size):
        xb = torch.tensor(X[i:i+batch_size], dtype=torch.float32, device=device)
        logits = model(xb)
        if n_classes == 2:
            prob = torch.sigmoid(logits.view(-1)).cpu().numpy()
            pred = (prob >= 0.5).astype(int)
        else:
            prob = torch.softmax(logits, dim=-1).cpu().numpy()
            pred = prob.argmax(axis=1)
        probs_list.append(prob); preds_list.append(pred)
    probs = np.concatenate(probs_list) if probs_list else np.array([])
    preds = np.concatenate(preds_list) if preds_list else np.array([])
    return probs, preds

def main():
    ap = argparse.ArgumentParser(description="ì¶”ë¡  ì „ìš© ìŠ¤í¬ë¦½íŠ¸ (ë¼ë²¨ ì—†ëŠ” ìƒˆ ë°ì´í„° ì˜ˆì¸¡)")
    ap.add_argument("--csv_path", type=str, required=True, help="ì˜ˆì¸¡í•  CSV íŒŒì¼ ê²½ë¡œ")
    ap.add_argument("--output", type=str, default=None, help="ê²°ê³¼ ì €ì¥ ê²½ë¡œ (ê¸°ë³¸: dl_outputs/predictions.csv)")
    ap.add_argument("--batch_size", type=int, default=512)
    args = ap.parse_args()

    print("="*60)
    print("ğŸ”® ì¶”ë¡  ëª¨ë“œ ì‹œì‘")
    print("="*60)
    
    # ì²´í¬í¬ì¸íŠ¸/ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
    print("\nğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")
    ckpt = load_ckpt()
    model = build_model(ckpt)
    scaler = joblib.load(os.path.join(OUTDIR, "scaler.joblib"))
    
    # ë©”íƒ€
    n_classes = int(ckpt["n_classes"])
    feature_cols = ckpt["feature_cols"]
    label_map = ckpt["label_map"]
    name_of = lambda i: label_map[str(i)] if isinstance(label_map, dict) and str(i) in label_map else label_map[i]
    
    print(f"   í´ë˜ìŠ¤ ì´ë¦„: {[name_of(i) for i in range(n_classes)]}")
    
    # ë°ì´í„° ë¡œë“œ
    print(f"\nğŸ“‚ ë°ì´í„° ë¡œë”©: {args.csv_path}")
    df = pd.read_csv(args.csv_path)
    print(f"   ì´ {len(df)}ê°œ ìƒ˜í”Œ")
    
    # íŠ¹ì§• ì •ë ¬ & ìŠ¤ì¼€ì¼ë§
    X = align_features(df, feature_cols)
    X = scaler.transform(X)
    
    # ì¶”ë¡ 
    print(f"\nğŸš€ ì¶”ë¡  ì¤‘...")
    probs, y_pred = infer(model, X, n_classes, batch_size=args.batch_size)
    
    print(f"âœ… ì¶”ë¡  ì™„ë£Œ!")
    
    # ì˜ˆì¸¡ ë¶„í¬ ì¶œë ¥
    unique, counts = np.unique(y_pred, return_counts=True)
    print(unique[0])
    print(counts[0])
    print(f"\nğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ë¶„í¬:")
    for cls, cnt in zip(unique, counts):
        print(f"   {name_of(cls)}: {cnt}ê°œ ({cnt/len(y_pred)*100:.1f}%)")
    
    # CSV ì €ì¥
    chunk_col = "chunk_name" if "chunk_name" in df.columns else None
    fn_col = "filename" if "filename" in df.columns else None
    
    out_rows = {
        "index": list(range(len(y_pred))),
        **({"chunk_name": df[chunk_col].values} if chunk_col else {}),
        **({"filename": df[fn_col].values} if fn_col else {}),
        "predicted_class": [name_of(i) for i in y_pred],
    }
    
    if n_classes == 2:
        out_rows["probability"] = probs
    else:
        # ë‹¤ì¤‘ í´ë˜ìŠ¤ëŠ” ê° í´ë˜ìŠ¤ë³„ í™•ë¥  ì €ì¥
        for i in range(n_classes):
            out_rows[f"prob_{name_of(i)}"] = probs[:, i]
    
    save_path = args.output if args.output else os.path.join(OUTDIR, "predictions.csv")
    pd.DataFrame(out_rows).to_csv(save_path, index=False, encoding="utf-8-sig")
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {save_path}")
    print("="*60)
    
if __name__ == "__main__": main()

# python backend/predict.py --csv_path /Users/parksung-cheol/Desktop/snoring/backend/mfcc_features.csv